{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyPAGE: Comprehensive Tutorial\n",
    "\n",
    "This notebook provides an end-to-end tutorial for **pyPAGE**, a Python implementation of the conditional-information PAGE framework for gene-set enrichment analysis. It covers:\n",
    "\n",
    "1. Loading gene sets (paired arrays, annotation files, GMT files)\n",
    "2. Loading expression data (continuous scores, pre-binned labels)\n",
    "3. Gene ID conversion with `GeneMapper` (offline, cached)\n",
    "4. Bulk PAGE analysis (MI/CMI, permutation testing, redundancy filtering, visualization)\n",
    "5. Single-cell PAGE analysis (per-cell scoring, spatial coherence, neighborhood mode)\n",
    "6. A complete integrated workflow combining GMT loading, gene ID mapping, and PAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Installation\n\nInstall pyPAGE from PyPI:\n\n```bash\npip install bio-pypage\n```\n\nOr install from source for development:\n\n```bash\ngit clone https://github.com/goodarzilab/pyPAGE\ncd pyPAGE\npip install -e .\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pypage import PAGE, ExpressionProfile, GeneSets, GeneMapper, SingleCellPAGE\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Loading Gene Sets\n",
    "\n",
    "`GeneSets` stores pathway/regulon annotations as a binary membership matrix. There are several ways to create one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. From Paired Arrays\n",
    "\n",
    "The simplest approach — provide two arrays of equal length: one with gene names, one with pathway names. Each pair defines a gene-pathway membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_arr = np.array(['TP53', 'TP53', 'BRCA1', 'BRCA1', 'MYC', 'MYC', 'EGFR'])\n",
    "pathways_arr = np.array(['Apoptosis', 'P53_Signaling', 'DNA_Repair', 'Apoptosis',\n",
    "                         'Cell_Cycle', 'Apoptosis', 'Cell_Cycle'])\n",
    "\n",
    "gs_arrays = GeneSets(genes=genes_arr, pathways=pathways_arr)\n",
    "print(gs_arrays)\n",
    "print(\"Genes:\", gs_arrays.genes)\n",
    "print(\"Pathways:\", gs_arrays.pathways)\n",
    "print(\"Bool array shape:\", gs_arrays.bool_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 1b. From Long-Format Files (Paired Arrays)\n\nMany annotation files are in long format — one gene-pathway pair per line. Load these with `pd.read_csv` and pass the two columns as paired arrays. The bundled GO Biological Process data is in this format:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "ann = pd.read_csv(\n    \"../example_data/GO_BP_2021_index.txt.gz\",\n    sep=\"\\t\", header=None, names=[\"gene\", \"pathway\"]\n)\nprint(\"Annotation file format (gene-pathway pairs):\")\nprint(ann.head())\n\ngs_ann = GeneSets(ann[\"gene\"], ann[\"pathway\"])\nprint(f\"\\n{gs_ann}\")\nprint(f\"Example pathways: {gs_ann.pathways[:3]}\")\nprint(f\"Example genes: {gs_ann.genes[:10]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "For **index-format** annotation files (one pathway per line, followed by all its genes), use `ann_file=`:\n\n```python\n# Pathway-first index file: PathwayA\\tGene1\\tGene2\\tGene3\ngs = GeneSets(ann_file=\"pathways_index.txt\")\n\n# Gene-first index file: Gene1\\tPathwayA\\tPathwayB\ngs = GeneSets(ann_file=\"genes_index.txt\", first_col_is_genes=True)\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. From GMT Files\n",
    "\n",
    "MSigDB distributes gene sets in GMT format. `GeneSets.from_gmt()` reads `.gmt` or `.gmt.gz` files directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_gmt = GeneSets.from_gmt(\"../example_data/example.gmt\")\n",
    "print(gs_gmt)\n",
    "print(\"Pathways:\", gs_gmt.pathways)\n",
    "print(\"Total genes:\", gs_gmt.n_genes)\n",
    "print(\"\\nPathway sizes:\")\n",
    "for pw in gs_gmt.pathways:\n",
    "    idx = np.where(gs_gmt.pathways == pw)[0][0]\n",
    "    size = gs_gmt.bool_array[idx].sum()\n",
    "    print(f\"  {pw}: {size} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMT files store an optional description field (second column). After loading, descriptions are accessible via the `descriptions` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pathway, desc in gs_gmt.descriptions.items():\n",
    "    print(f\"{pathway}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. Filtering Pathways by Size\n",
    "\n",
    "You can filter pathways by minimum/maximum gene count, either at load time or afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter at load time\n",
    "gs_filtered = GeneSets.from_gmt(\"../example_data/example.gmt\", min_size=15, max_size=500)\n",
    "print(f\"After filtering: {gs_filtered.n_pathways} pathways\")\n",
    "\n",
    "# Or filter after loading\n",
    "gs_gmt2 = GeneSets.from_gmt(\"../example_data/example.gmt\")\n",
    "print(f\"Before filter: {gs_gmt2.n_pathways} pathways\")\n",
    "gs_gmt2.filter_pathways(min_size=18)\n",
    "print(f\"After filter (min_size=18): {gs_gmt2.n_pathways} pathways\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e. Exporting to GMT\n",
    "\n",
    "Export any `GeneSets` object to GMT format with `to_gmt()`. This enables round-trip loading and saving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, os\n",
    "\n",
    "# Round-trip: load -> export -> reload\n",
    "gs_original = GeneSets.from_gmt(\"../example_data/example.gmt\")\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    out_path = os.path.join(tmpdir, \"exported.gmt\")\n",
    "    gs_original.to_gmt(out_path)\n",
    "    \n",
    "    # Reload and verify\n",
    "    gs_reloaded = GeneSets.from_gmt(out_path)\n",
    "    print(f\"Original: {gs_original.n_pathways} pathways, {gs_original.n_genes} genes\")\n",
    "    print(f\"Reloaded: {gs_reloaded.n_pathways} pathways, {gs_reloaded.n_genes} genes\")\n",
    "    print(f\"Pathways match: {set(gs_original.pathways) == set(gs_reloaded.pathways)}\")\n",
    "    print(f\"Genes match: {set(gs_original.genes) == set(gs_reloaded.genes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1f. Inspecting a GeneSets Object\n",
    "\n",
    "Key attributes:\n",
    "- `genes` — sorted array of gene names\n",
    "- `pathways` — sorted array of pathway names\n",
    "- `bool_array` — binary matrix of shape `(n_pathways, n_genes)`\n",
    "- `membership` — per-gene count of pathway memberships (used for CMI bias correction)\n",
    "- `n_genes`, `n_pathways` — counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GeneSets.from_gmt(\"../example_data/example.gmt\")\n",
    "print(gs)\n",
    "print(f\"Bool array shape: {gs.bool_array.shape}\")\n",
    "print(f\"Membership (first 10 genes): {gs.membership[:10]}\")\n",
    "print(f\"Genes in multiple pathways: {(gs.membership > 1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Loading Expression Data\n",
    "\n",
    "`ExpressionProfile` holds gene expression data. It accepts either continuous scores (which are auto-discretized into bins) or pre-binned integer labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Continuous Scores (Auto-Binned)\n",
    "\n",
    "When `is_bin=False` (the default), continuous expression values are discretized into `n_bins` equal-frequency bins when `get_gene_subset()` is called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic continuous expression data\n",
    "gene_names = np.array([f'Gene{i}' for i in range(200)])\n",
    "scores = np.random.randn(200)  # continuous differential expression scores\n",
    "\n",
    "exp_continuous = ExpressionProfile(gene_names, scores, is_bin=False, n_bins=10)\n",
    "print(exp_continuous)\n",
    "print(f\"Raw expression range: [{scores.min():.2f}, {scores.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Pre-Binned Labels\n",
    "\n",
    "When `is_bin=True`, the expression array is treated as integer bin assignments. This is common when working with pre-processed rank data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the example pre-binned data\n",
    "expr_df = pd.read_csv(\n",
    "    \"../example_data/AP2S1.tab.gz\",\n",
    "    sep=\"\\t\", header=None, names=[\"gene\", \"bin\"]\n",
    ")\n",
    "print(expr_df.head())\n",
    "\n",
    "exp_binned = ExpressionProfile(expr_df[\"gene\"], expr_df[\"bin\"], is_bin=True)\n",
    "print(f\"\\n{exp_binned}\")\n",
    "print(f\"Unique bins: {np.unique(expr_df['bin'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Inspecting an ExpressionProfile\n",
    "\n",
    "Key attributes:\n",
    "- `genes` — gene names\n",
    "- `n_genes` — number of genes\n",
    "- `n_bins` — number of bins\n",
    "- `raw_expression` — the original expression/bin values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_binned)\n",
    "print(f\"Genes (first 5): {exp_binned.genes[:5]}\")\n",
    "print(f\"Expression shape: {exp_binned.raw_expression.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Gene ID Conversion\n",
    "\n",
    "Gene sets and expression data sometimes use different ID types (Ensembl IDs, gene symbols, Entrez IDs). pyPAGE provides two approaches for conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. GeneMapper — Offline Cached Mapping (Recommended)\n",
    "\n",
    "`GeneMapper` downloads a gene ID mapping table from Ensembl BioMart once and caches it locally (~5 MB at `~/.pypage/`). Subsequent calls load from cache with no network needed.\n",
    "\n",
    "**Supported ID types:** `'ensg'`, `'symbol'`, `'entrez'`\n",
    "\n",
    "For this tutorial, we'll create a small mock cache file so the notebook runs fully offline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, os\n",
    "\n",
    "# Create a mock gene mapping cache (normally GeneMapper downloads this from Ensembl)\n",
    "mock_cache_dir = tempfile.mkdtemp()\n",
    "mock_tsv = os.path.join(mock_cache_dir, \"gene_map_human.tsv\")\n",
    "\n",
    "mock_data = \"\"\"ensg\\tsymbol\\tentrez\n",
    "ENSG00000141510\\tTP53\\t7157\n",
    "ENSG00000012048\\tBRCA1\\t672\n",
    "ENSG00000136997\\tMYC\\t4609\n",
    "ENSG00000146648\\tEGFR\\t1956\n",
    "ENSG00000157764\\tBRAF\\t673\n",
    "ENSG00000171862\\tPTEN\\t5728\n",
    "ENSG00000133703\\tKRAS\\t3845\n",
    "ENSG00000149311\\tATM\\t472\n",
    "ENSG00000139618\\tBRCA2\\t675\n",
    "ENSG00000116044\\tNFE2L2\\t4780\n",
    "ENSG00000164362\\tTERT\\t7015\n",
    "ENSG00000118058\\tKMT2A\\t4297\n",
    "ENSG00000181555\\tSETBP1\\t26040\n",
    "ENSG00000168036\\tCTNNB1\\t1499\n",
    "ENSG00000196712\\tNF1\\t4763\n",
    "ENSG00000134086\\tVHL\\t7428\n",
    "ENSG00000183765\\tCASP3\\t836\n",
    "ENSG00000164305\\tCASP7\\t840\n",
    "ENSG00000064012\\tCASP8\\t841\n",
    "ENSG00000132906\\tCASP9\\t842\n",
    "ENSG00000087088\\tBAX\\t581\n",
    "ENSG00000030110\\tBAK1\\t578\n",
    "ENSG00000171791\\tBCL2\\t596\n",
    "ENSG00000171552\\tBCL2L1\\t598\n",
    "ENSG00000015475\\tBID\\t637\n",
    "ENSG00000172115\\tCYCS\\t54205\n",
    "ENSG00000120868\\tAPAF1\\t317\n",
    "ENSG00000184047\\tDIABLO\\t56616\n",
    "ENSG00000101966\\tXIAP\\t331\n",
    "ENSG00000110330\\tBIRC2\\t329\n",
    "ENSG00000023445\\tBIRC3\\t330\n",
    "ENSG00000168040\\tFADD\\t8772\n",
    "ENSG00000026103\\tFAS\\t355\n",
    "ENSG00000117560\\tFASLG\\t356\n",
    "ENSG00000104689\\tTNFRSF10A\\t8797\n",
    "ENSG00000120889\\tTNFRSF10B\\t8795\n",
    "ENSG00000073111\\tMDM2\\t4193\n",
    "ENSG00000198625\\tMDM4\\t4194\n",
    "ENSG00000124762\\tCDKN1A\\t1026\n",
    "ENSG00000147889\\tCDKN2A\\t1029\n",
    "\"\"\"\n",
    "\n",
    "with open(mock_tsv, 'w') as f:\n",
    "    f.write(mock_data)\n",
    "\n",
    "print(f\"Mock cache created at: {mock_cache_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeneMapper pointing at our mock cache\n",
    "mapper = GeneMapper(species='human', cache_dir=mock_cache_dir)\n",
    "\n",
    "# Convert Ensembl IDs to gene symbols\n",
    "ensg_ids = ['ENSG00000141510', 'ENSG00000012048', 'ENSG00000136997', 'ENSG00000000000']\n",
    "symbols, unmapped = mapper.convert(ensg_ids, from_type='ensg', to_type='symbol')\n",
    "\n",
    "print(\"Input Ensembl IDs:\", ensg_ids)\n",
    "print(\"Converted symbols:\", symbols)\n",
    "print(\"Unmapped IDs:\", unmapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert gene symbols to Entrez IDs\n",
    "symbols_in = ['TP53', 'BRCA1', 'MYC']\n",
    "entrez_ids, unmapped = mapper.convert(symbols_in, from_type='symbol', to_type='entrez')\n",
    "\n",
    "print(\"Symbols:\", symbols_in)\n",
    "print(\"Entrez IDs:\", entrez_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeneMapper also handles versioned Ensembl IDs (strips the version suffix)\n",
    "versioned = ['ENSG00000141510.15', 'ENSG00000012048.23']\n",
    "result, _ = mapper.convert(versioned, from_type='ensg', to_type='symbol')\n",
    "print(\"Versioned IDs:\", versioned)\n",
    "print(\"Resolved:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. GeneSets.map_genes() — Convert Gene IDs In-Place\n",
    "\n",
    "`map_genes()` uses a `GeneMapper` to convert all gene IDs in a `GeneSets` object. Unmapped genes are dropped automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeneSets with Ensembl IDs (using genes from our mock cache)\n",
    "ensg_genes = np.array([\n",
    "    'ENSG00000183765', 'ENSG00000183765',  # CASP3 -> Apoptosis, P53_Pathway\n",
    "    'ENSG00000087088', 'ENSG00000087088',  # BAX -> Apoptosis, P53_Pathway\n",
    "    'ENSG00000141510', 'ENSG00000141510',  # TP53 -> P53_Pathway, DNA_Repair\n",
    "    'ENSG00000012048',                       # BRCA1 -> DNA_Repair\n",
    "])\n",
    "pw = np.array([\n",
    "    'Apoptosis', 'P53_Pathway',\n",
    "    'Apoptosis', 'P53_Pathway',\n",
    "    'P53_Pathway', 'DNA_Repair',\n",
    "    'DNA_Repair',\n",
    "])\n",
    "\n",
    "gs_ensg = GeneSets(genes=ensg_genes, pathways=pw)\n",
    "print(\"Before mapping:\")\n",
    "print(f\"  Genes: {gs_ensg.genes}\")\n",
    "\n",
    "# Convert Ensembl IDs to gene symbols\n",
    "gs_ensg.map_genes(mapper, from_type='ensg', to_type='symbol')\n",
    "print(\"\\nAfter mapping:\")\n",
    "print(f\"  Genes: {gs_ensg.genes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Legacy: convert_from_to() (Requires Network)\n",
    "\n",
    "`ExpressionProfile.convert_from_to()`, `GeneSets.convert_from_to()`, and `Heatmap.convert_from_to()` use Ensembl BioMart via `pybiomart` and require an internet connection:\n",
    "\n",
    "```python\n",
    "# Example (not run — requires network)\n",
    "exp.convert_from_to('refseq', 'ensg', 'human')\n",
    "gs.convert_from_to('ensg', 'gs', 'human')\n",
    "```\n",
    "\n",
    "**Recommendation:** Prefer `GeneMapper` for offline, reproducible workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Bulk PAGE Analysis\n",
    "\n",
    "The core `PAGE` class performs pathway enrichment analysis on bulk expression data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Setting Up PAGE\n",
    "\n",
    "Load expression and gene set data, then initialize a `PAGE` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load pre-binned expression data\nexpr_df = pd.read_csv(\n    \"../example_data/AP2S1.tab.gz\",\n    sep=\"\\t\", header=None, names=[\"gene\", \"bin\"]\n)\nexp = ExpressionProfile(expr_df[\"gene\"], expr_df[\"bin\"], is_bin=True)\n\n# Load GO Biological Process annotations (long-format: gene, pathway pairs)\nann = pd.read_csv(\n    \"../example_data/GO_BP_2021_index.txt.gz\",\n    sep=\"\\t\", header=None, names=[\"gene\", \"pathway\"]\n)\ngs = GeneSets(ann[\"gene\"], ann[\"pathway\"])\n\nprint(exp)\nprint(gs)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Key `PAGE` parameters:\n\n| Parameter | Default | Description |\n|-----------|---------|-------------|\n| `function` | `'cmi'` | `'cmi'` (conditional MI, corrects annotation bias) or `'mi'` (standard MI) |\n| `n_shuffle` | `10000` | Number of permutations for significance testing |\n| `alpha` | `0.005` | P-value threshold for informative pathways |\n| `k` | `20` | Early-stopping: stop after k consecutive non-significant pathways |\n| `filter_redundant` | `True` | Whether to remove redundant pathways (default: on) |\n| `redundancy_ratio` | `5.0` | CMI/MI ratio threshold; pathways with all ratios above this are kept |\n| `n_jobs` | `1` | Number of parallel threads |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Running the Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use small n_shuffle for speed in this tutorial\n",
    "p = PAGE(exp, gs, n_shuffle=50, k=7, filter_redundant=False)\n",
    "results, heatmap = p.run()\n",
    "\n",
    "print(f\"Found {len(results)} significant pathways\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Interpreting the Results DataFrame\n",
    "\n",
    "The results DataFrame has these columns:\n",
    "- **pathway** — pathway name\n",
    "- **CMI** — conditional mutual information (or MI if `function='mi'`)\n",
    "- **p-value** — empirical p-value from permutation test\n",
    "- **Regulation pattern** — `1` for upregulated, `-1` for downregulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d. Visualizing the Heatmap\n",
    "\n",
    "The `Heatmap` object shows per-bin enrichment patterns for significant pathways. Positive values (yellow/bright) indicate overrepresentation; negative (dark/purple) indicate underrepresentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if heatmap is not None:\n",
    "    heatmap.show(max_rows=20, title='GO BP Enrichment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4e. Extracting Enriched Genes per Pathway\n",
    "\n",
    "`get_enriched_genes()` returns a list of arrays, one per expression bin, showing which pathway genes fall in each bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results) > 0:\n",
    "    pathway_name = results.iloc[0]['pathway']\n",
    "    enriched = p.get_enriched_genes(pathway_name)\n",
    "    print(f\"Genes in '{pathway_name}' by expression bin:\")\n",
    "    for i, genes_in_bin in enumerate(enriched):\n",
    "        if len(genes_in_bin) > 0:\n",
    "            print(f\"  Bin {i}: {genes_in_bin[:5]}{'...' if len(genes_in_bin) > 5 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4f. Getting the Enrichment Score Matrix\n",
    "\n",
    "`get_es_matrix()` returns a DataFrame with log10 hypergeometric p-values per pathway and bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if heatmap is not None:\n",
    "    es_matrix = p.get_es_matrix()\n",
    "    print(f\"ES matrix shape: {es_matrix.shape}\")\n",
    "    es_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4g. MI vs CMI Comparison\n",
    "\n",
    "CMI (conditional mutual information) accounts for annotation bias by conditioning on gene membership counts. Let's compare MI and CMI results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with MI\n",
    "np.random.seed(42)\n",
    "p_mi = PAGE(exp, gs, function='mi', n_shuffle=50, k=7)\n",
    "results_mi, _ = p_mi.run()\n",
    "\n",
    "# Run with CMI\n",
    "np.random.seed(42)\n",
    "p_cmi = PAGE(exp, gs, function='cmi', n_shuffle=50, k=7)\n",
    "results_cmi, _ = p_cmi.run()\n",
    "\n",
    "print(f\"MI found {len(results_mi)} significant pathways\")\n",
    "print(f\"CMI found {len(results_cmi)} significant pathways\")\n",
    "\n",
    "if len(results_mi) > 0 and len(results_cmi) > 0:\n",
    "    mi_pathways = set(results_mi['pathway'])\n",
    "    cmi_pathways = set(results_cmi['pathway'])\n",
    "    print(f\"\\nOverlap: {len(mi_pathways & cmi_pathways)} pathways\")\n",
    "    print(f\"MI-only: {len(mi_pathways - cmi_pathways)} pathways\")\n",
    "    print(f\"CMI-only: {len(cmi_pathways - mi_pathways)} pathways\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4h. Redundancy Filtering\n",
    "\n",
    "When `filter_redundant=True`, PAGE removes pathways that are redundant with already-accepted pathways, based on conditional mutual information between pathway memberships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "np.random.seed(42)\np_red = PAGE(exp, gs, n_shuffle=50, k=7, filter_redundant=True)\nresults_red, _ = p_red.run()\n\nprint(f\"Without redundancy filter: {len(results_cmi)} pathways\")\nprint(f\"With redundancy filter: {len(results_red)} pathways\")\n\n# Inspect which pathways were filtered and why\nkilled = p_red.get_redundancy_log()\nif len(killed) > 0:\n    print(f\"\\nFiltered {len(killed)} redundant pathways:\")\n    print(killed.head(10))\n\n# full_results includes all informative pathways with a 'redundant' flag\nprint(f\"\\nAll informative pathways (including redundant):\")\nprint(p_red.full_results.head(10))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4i. Reproducibility\n",
    "\n",
    "For fully deterministic results, set a random seed and use a single thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Reload data fresh for a clean reproducibility test\nexpr_df_ = pd.read_csv(\"../example_data/AP2S1.tab.gz\", sep=\"\\t\", header=None, names=[\"gene\", \"bin\"])\nann_ = pd.read_csv(\"../example_data/GO_BP_2021_index.txt.gz\", sep=\"\\t\", header=None, names=[\"gene\", \"pathway\"])\n\nnp.random.seed(0)\nexp1 = ExpressionProfile(expr_df_[\"gene\"], expr_df_[\"bin\"], is_bin=True)\ngs1 = GeneSets(ann_[\"gene\"], ann_[\"pathway\"])\np1 = PAGE(exp1, gs1, n_shuffle=50, k=7, n_jobs=1)\nr1, _ = p1.run()\n\nnp.random.seed(0)\nexp2 = ExpressionProfile(expr_df_[\"gene\"], expr_df_[\"bin\"], is_bin=True)\ngs2 = GeneSets(ann_[\"gene\"], ann_[\"pathway\"])\np2 = PAGE(exp2, gs2, n_shuffle=50, k=7, n_jobs=1)\nr2, _ = p2.run()\n\nif len(r1) > 0 and len(r2) > 0 and len(r1) == len(r2):\n    match = (r1['pathway'].values == r2['pathway'].values).all()\n    print(f\"Results identical with same seed: {match}\")\n    print(f\"Both runs found {len(r1)} significant pathways\")\nelse:\n    print(f\"Run 1: {len(r1)} pathways, Run 2: {len(r2)} pathways\")"
  },
  {
   "cell_type": "code",
   "source": "# Pick two known pathways from the gene sets\navailable_pathways = list(gs.pathways[:5])\nprint(f\"Example pathways: {available_pathways}\")\n\n# Run manual analysis on specific pathways\np_manual = PAGE(exp, gs, n_shuffle=50, k=7)\nmanual_results, manual_hm = p_manual.run_manual(available_pathways[:2])\nprint(f\"\\nManual analysis results ({len(manual_results)} pathways):\")\nprint(manual_results)\n\n# Note: p-values are NaN since no permutation testing is performed\nif manual_hm is not None:\n    manual_hm.show(title='Manual Pathway Analysis')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 4j. Manual Pathway Analysis\n\nUse `run_manual()` to analyze specific pathways of interest without permutation testing or redundancy filtering. This is useful for inspecting known pathways:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Single-Cell PAGE Analysis\n",
    "\n",
    "`SingleCellPAGE` computes per-cell pathway activity scores using MI/CMI, then tests spatial coherence of pathway scores across the cell manifold using Geary's C statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Creating Synthetic Single-Cell Data\n",
    "\n",
    "We'll create a synthetic dataset with two cell clusters and pathways with known differential activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_cells = 200\n",
    "n_genes_sc = 100\n",
    "n_cluster1 = 100\n",
    "\n",
    "gene_names_sc = np.array([f'Gene{i}' for i in range(n_genes_sc)])\n",
    "\n",
    "# Base expression\n",
    "X = np.random.rand(n_cells, n_genes_sc) * 5\n",
    "\n",
    "# Cluster 1 (cells 0-99): upregulate genes 0-19 (\"pathway A\" genes)\n",
    "X[:n_cluster1, :20] += 4\n",
    "\n",
    "# Cluster 2 (cells 100-199): upregulate genes 20-39 (\"pathway B\" genes)\n",
    "X[n_cluster1:, 20:40] += 4\n",
    "\n",
    "# Create a 2D embedding (two clusters)\n",
    "embedding = np.zeros((n_cells, 2))\n",
    "embedding[:n_cluster1] = np.random.randn(n_cluster1, 2) + np.array([3, 0])\n",
    "embedding[n_cluster1:] = np.random.randn(n_cells - n_cluster1, 2) + np.array([-3, 0])\n",
    "\n",
    "# Cluster labels\n",
    "labels = np.array(['Cluster_A'] * n_cluster1 + ['Cluster_B'] * (n_cells - n_cluster1))\n",
    "\n",
    "print(f\"Expression matrix: {X.shape}\")\n",
    "print(f\"Embedding: {embedding.shape}\")\n",
    "print(f\"Clusters: {np.unique(labels, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gene sets with known cluster-specific activity\n",
    "gs_genes = np.concatenate([\n",
    "    gene_names_sc[:20],       # Pathway_A genes\n",
    "    gene_names_sc[20:40],     # Pathway_B genes\n",
    "    gene_names_sc[50:65],     # Pathway_C genes (no cluster bias)\n",
    "])\n",
    "gs_pathways = np.concatenate([\n",
    "    np.repeat('Pathway_A', 20),\n",
    "    np.repeat('Pathway_B', 20),\n",
    "    np.repeat('Pathway_C', 15),\n",
    "])\n",
    "\n",
    "gs_sc = GeneSets(genes=gs_genes, pathways=gs_pathways)\n",
    "print(gs_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Creating an AnnData Object\n",
    "\n",
    "`SingleCellPAGE` works natively with AnnData objects (the standard for single-cell Python tools):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "\n",
    "adata = anndata.AnnData(\n",
    "    X=X,\n",
    "    var=pd.DataFrame(index=gene_names_sc),\n",
    "    obs=pd.DataFrame({'cluster': labels}),\n",
    ")\n",
    "adata.obsm['X_umap'] = embedding\n",
    "\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5c. Running Per-Cell Scoring + Spatial Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "sc_page = SingleCellPAGE(\n",
    "    adata=adata,\n",
    "    genesets=gs_sc,\n",
    "    function='cmi',\n",
    "    n_bins=5,\n",
    ")\n",
    "print(sc_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with reduced permutations for speed\n",
    "sc_results = sc_page.run(n_permutations=200)\n",
    "sc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5d. Interpreting Results\n",
    "\n",
    "The results DataFrame contains:\n",
    "- **pathway** — pathway name\n",
    "- **consistency** — spatial autocorrelation score (C' = 1 - Geary's C). Higher values mean pathway scores are more spatially coherent across the cell manifold.\n",
    "- **p-value** — empirical p-value from permutation test with size-matched random gene sets\n",
    "- **FDR** — Benjamini-Hochberg corrected p-value\n",
    "\n",
    "Pathways A and B should show high consistency (their activity is clustered), while Pathway C (random) should not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sc_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5e. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathway scores on UMAP embedding\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "for i, pw in enumerate(gs_sc.pathways):\n",
    "    sc_page.plot_pathway_on_embedding(pw, embedding_key='X_umap', ax=axes[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency ranking bar plot\n",
    "sc_page.plot_consistency_ranking(top_n=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of pathway scores across clusters\n",
    "sc_page.plot_pathway_heatmap(adata.obs['cluster'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5f. Accessing the Per-Cell Score Matrix\n",
    "\n",
    "The per-cell pathway scores are stored as a `(n_cells, n_pathways)` matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Score matrix shape: {sc_page.scores.shape}\")\n",
    "\n",
    "# Convert to a DataFrame for easy inspection\n",
    "scores_df = pd.DataFrame(\n",
    "    sc_page.scores,\n",
    "    columns=sc_page.pathway_names,\n",
    ")\n",
    "scores_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5g. Neighborhood Mode\n",
    "\n",
    "`run_neighborhoods()` aggregates cells by cluster label (or random micro-pools), computes mean expression per group, and runs standard bulk PAGE on each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "summary, group_results = sc_page.run_neighborhoods(labels=adata.obs['cluster'])\n",
    "print(\"Summary:\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "for group, (res_df, hm) in group_results.items():\n",
    "    print(f\"\\nGroup '{group}': {len(res_df)} significant pathways\")\n",
    "    if len(res_df) > 0:\n",
    "        print(res_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5h. Alternative Inputs\n",
    "\n",
    "You don't need an AnnData object — `SingleCellPAGE` also accepts raw numpy arrays or a precomputed KNN connectivity matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From numpy arrays\n",
    "sc_numpy = SingleCellPAGE(\n",
    "    expression=X,\n",
    "    genes=gene_names_sc,\n",
    "    genesets=gs_sc,\n",
    "    function='mi',\n",
    "    n_bins=5,\n",
    ")\n",
    "print(sc_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# With precomputed connectivity (e.g., from scanpy)\nfrom pypage.spatial import build_knn_graph\n\nW = build_knn_graph(X, k=15)\nsc_precomputed = SingleCellPAGE(\n    expression=X,\n    genes=gene_names_sc,\n    genesets=gs_sc,\n    connectivity=W,\n)\nprint(sc_precomputed)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Complete Workflow: GMT + GeneMapper + PAGE\n",
    "\n",
    "This section demonstrates a realistic end-to-end workflow that combines GMT loading, gene ID mapping, and PAGE analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load gene sets from GMT\n",
    "gs_workflow = GeneSets.from_gmt(\"../example_data/example.gmt\")\n",
    "print(f\"Loaded {gs_workflow.n_pathways} pathways with {gs_workflow.n_genes} genes\")\n",
    "print(f\"Gene ID format: {gs_workflow.genes[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create expression data using gene symbols (matching the GMT)\n",
    "# In a real workflow, you might need to convert IDs first.\n",
    "# Here the GMT already uses symbols, so we create matching expression data.\n",
    "\n",
    "all_genes = gs_workflow.genes.copy()\n",
    "# Add some extra genes not in the gene sets (realistic scenario)\n",
    "extra_genes = np.array([f'ExtraGene{i}' for i in range(50)])\n",
    "all_expr_genes = np.concatenate([all_genes, extra_genes])\n",
    "expression_values = np.random.randn(len(all_expr_genes))\n",
    "\n",
    "exp_workflow = ExpressionProfile(all_expr_genes, expression_values, n_bins=5)\n",
    "print(f\"Expression: {exp_workflow.n_genes} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Run PAGE\n",
    "np.random.seed(42)\n",
    "p_workflow = PAGE(exp_workflow, gs_workflow, n_shuffle=50, k=5)\n",
    "results_workflow, hm_workflow = p_workflow.run()\n",
    "\n",
    "print(f\"Shared genes: {len(p_workflow.shared_genes)}\")\n",
    "print(f\"Significant pathways: {len(results_workflow)}\")\n",
    "if len(results_workflow) > 0:\n",
    "    print(results_workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize\n",
    "if hm_workflow is not None:\n",
    "    hm_workflow.show(title='GMT Workflow Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 7. Parameter Reference\n\n### PAGE Parameters\n\n| Parameter | Type | Default | Description |\n|-----------|------|---------|-------------|\n| `expression` | `ExpressionProfile` | — | Expression data (required) |\n| `genesets` | `GeneSets` | — | Gene set annotations (required) |\n| `function` | `str` | `'cmi'` | `'cmi'` for conditional MI (recommended), `'mi'` for standard MI |\n| `n_shuffle` | `int` | `10000` | Number of permutations for significance testing |\n| `alpha` | `float` | `0.005` | P-value significance threshold |\n| `k` | `int` | `20` | Early stopping: consecutive non-significant pathways before stopping |\n| `filter_redundant` | `bool` | `True` | Remove redundant pathways using CMI |\n| `redundancy_ratio` | `float` | `5.0` | CMI/MI ratio threshold; pathways with all ratios above this are kept |\n| `n_jobs` | `int` | `1` | Number of parallel threads |\n\n### SingleCellPAGE Parameters\n\n| Parameter | Type | Default | Description |\n|-----------|------|---------|-------------|\n| `adata` | `AnnData` | `None` | AnnData object (alternative: `expression` + `genes`) |\n| `expression` | `np.ndarray` | `None` | (n_cells, n_genes) expression matrix |\n| `genes` | `np.ndarray` | `None` | Gene names array |\n| `genesets` | `GeneSets` | — | Gene set annotations (required) |\n| `function` | `str` | `'cmi'` | `'cmi'` or `'mi'` |\n| `n_bins` | `int` | `10` | Number of bins for expression discretization |\n| `n_neighbors` | `int` | `ceil(sqrt(n_cells))` | Number of KNN neighbors (capped at 100) |\n| `connectivity` | `sparse matrix` | `None` | Precomputed cell-cell connectivity |\n\n### GeneMapper Parameters\n\n| Parameter | Type | Default | Description |\n|-----------|------|---------|-------------|\n| `species` | `str` | `'human'` | `'human'` or `'mouse'` |\n| `cache_dir` | `str` | `'~/.pypage/'` | Directory for the cached mapping file |\n\n### GeneSets.from_gmt() Parameters\n\n| Parameter | Type | Default | Description |\n|-----------|------|---------|-------------|\n| `gmt_file` | `str` | — | Path to `.gmt` or `.gmt.gz` file |\n| `n_bins` | `int` | `3` | Number of bins for membership binning |\n| `min_size` | `int` | `None` | Minimum pathway size (filter after loading) |\n| `max_size` | `int` | `None` | Maximum pathway size (filter after loading) |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GMT with gene symbols\n",
    "gs_convert = GeneSets.from_gmt(\"../example_data/example.gmt\")\n",
    "print(f\"GMT genes (symbols): {gs_convert.genes[:5]}\")\n",
    "\n",
    "# Suppose our expression data uses Ensembl IDs.\n",
    "# We can convert the GeneSets to use Ensembl IDs to match,\n",
    "# or convert the expression data. Let's convert GeneSets -> Ensembl:\n",
    "\n",
    "# First, let's see which GMT genes are in our mock mapper\n",
    "test_result, test_unmapped = mapper.convert(\n",
    "    gs_convert.genes, from_type='symbol', to_type='ensg'\n",
    ")\n",
    "n_mapped = sum(1 for x in test_result if x is not None)\n",
    "print(f\"\\nMappable genes: {n_mapped}/{len(gs_convert.genes)}\")\n",
    "\n",
    "# Convert gene symbols -> Ensembl IDs\n",
    "gs_convert.map_genes(mapper, from_type='symbol', to_type='ensg')\n",
    "print(f\"After conversion: {gs_convert.n_genes} genes (Ensembl IDs)\")\n",
    "print(f\"Example genes: {gs_convert.genes[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Parameter Reference\n",
    "\n",
    "### PAGE Parameters\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|-----------|------|---------|-------------|\n",
    "| `expression` | `ExpressionProfile` | — | Expression data (required) |\n",
    "| `genesets` | `GeneSets` | — | Gene set annotations (required) |\n",
    "| `function` | `str` | `'cmi'` | `'cmi'` for conditional MI (recommended), `'mi'` for standard MI |\n",
    "| `n_shuffle` | `int` | `1000` | Number of permutations for significance testing |\n",
    "| `alpha` | `float` | `0.01` | P-value significance threshold |\n",
    "| `k` | `int` | `10` | Early stopping: consecutive non-significant pathways before stopping |\n",
    "| `filter_redundant` | `bool` | `False` | Remove redundant pathways using CMI |\n",
    "| `redundancy_ratio` | `float` | `0.1` | Redundancy threshold (higher = stricter filtering) |\n",
    "| `n_jobs` | `int` | `1` | Number of parallel threads |\n",
    "\n",
    "### SingleCellPAGE Parameters\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|-----------|------|---------|-------------|\n",
    "| `adata` | `AnnData` | `None` | AnnData object (alternative: `expression` + `genes`) |\n",
    "| `expression` | `np.ndarray` | `None` | (n_cells, n_genes) expression matrix |\n",
    "| `genes` | `np.ndarray` | `None` | Gene names array |\n",
    "| `genesets` | `GeneSets` | — | Gene set annotations (required) |\n",
    "| `function` | `str` | `'cmi'` | `'cmi'` or `'mi'` |\n",
    "| `n_bins` | `int` | `10` | Number of bins for expression discretization |\n",
    "| `n_neighbors` | `int` | `ceil(sqrt(n_cells))` | Number of KNN neighbors (capped at 100) |\n",
    "| `connectivity` | `sparse matrix` | `None` | Precomputed cell-cell connectivity |\n",
    "\n",
    "### GeneMapper Parameters\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|-----------|------|---------|-------------|\n",
    "| `species` | `str` | `'human'` | `'human'` or `'mouse'` |\n",
    "| `cache_dir` | `str` | `'~/.pypage/'` | Directory for the cached mapping file |\n",
    "\n",
    "### GeneSets.from_gmt() Parameters\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|-----------|------|---------|-------------|\n",
    "| `gmt_file` | `str` | — | Path to `.gmt` or `.gmt.gz` file |\n",
    "| `n_bins` | `int` | `3` | Number of bins for membership binning |\n",
    "| `min_size` | `int` | `None` | Minimum pathway size (filter after loading) |\n",
    "| `max_size` | `int` | `None` | Maximum pathway size (filter after loading) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 8. Next Steps\n\n- **API Reference:** See `MANUAL.md` for the complete API documentation.\n- **More examples:** See `notebooks/pyPAGE_bulk_and_sc_example.ipynb` and `notebooks/single_cell_page_tutorial.ipynb` for additional worked examples.\n- **Citation:** If you use pyPAGE in your research, please cite:\n\n> Bakulin A, Teyssier NB, Kampmann M, Khoroshkin M, Goodarzi H (2024)  \n> *pyPAGE: A framework for Addressing biases in gene-set enrichment analysis — A case study on Alzheimer's disease.*  \n> PLoS Computational Biology 20(9): e1012346.  \n> https://doi.org/10.1371/journal.pcbi.1012346"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup mock cache\n",
    "import shutil\n",
    "shutil.rmtree(mock_cache_dir, ignore_errors=True)\n",
    "print(\"Tutorial complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}